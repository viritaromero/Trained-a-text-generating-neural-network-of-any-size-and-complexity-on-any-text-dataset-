{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Interactive textgenrnn w/ GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "outputId": "2de3667f-e57c-42e3-a968-601772f1cadb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q textgenrnn\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set the textgenrnn model configuration here: the default parameters here give good results for most workflows. (see the [demo notebook](https://github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb) for more information about these parameters)\n",
        "\n",
        "If you are using an input file where documents are line-delimited, make sure to set `line_delimited` to `True`."
      ]
    },
    {
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 30,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': False,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 20,   # set higher to train the model for longer\n",
        "    'gen_epochs': 5,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_name = \"tales.txt\"\n",
        "model_name = 'colaboratory'   # change to set file name of resulting trained models/texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next cell will start the actual training. And thanks to the power of Keras's CuDNN layers, training is super-fast when compared to CPU training on a local machine!\n",
        "\n",
        "Ideally, you want a training loss less than `1.0` in order for the model to create sensible text consistently."
      ]
    },
    {
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "98be9a69-a5a2-42df-821c-a3f813d71876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5205
        }
      },
      "cell_type": "code",
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training new model w/ 3-layer, 128-cell LSTMs\n",
            "Training on 401,503 character sequences.\n",
            "Epoch 1/20\n",
            "392/392 [==============================] - 73s 185ms/step - loss: 3.1164\n",
            "Epoch 2/20\n",
            "392/392 [==============================] - 67s 172ms/step - loss: 2.0227\n",
            "Epoch 3/20\n",
            "392/392 [==============================] - 67s 171ms/step - loss: 1.5656\n",
            "Epoch 4/20\n",
            "392/392 [==============================] - 67s 171ms/step - loss: 1.3868\n",
            "Epoch 5/20\n",
            "392/392 [==============================] - 67s 171ms/step - loss: 1.2883\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            " and said, “I will go and be for it, and the maiden was all the world. And the maiden was a said, “I am the tree in the world be for a contre, and the King and the second in the world. And the second more the tree in the water, and the King’s Son and the beautiful was all the forest, and the beautif\n",
            "\n",
            " a miller and the third said, “What is you are you are you are of the window. The mother said, “I am to the beautiful morning, and the mother said, “I am the second in the world, and the King’s Son had to the water and the forest and said, “I will go and the beautiful and began to the third day to t\n",
            "\n",
            " came to a little could be a country, and said, “I will go to the beautiful man and said, “I will go not be a contry of the wild for a long before the world.\n",
            "\n",
            "And the mother said, “I will go to him, and the King’s Son and said, “I will not be a beautiful thirsty strange and the second with all the w\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "The maiden he gronting to the forest. And when the King was singing to the cocks and presented in the golden flowers and the door, and let her in her forth, and he had a said, “I will stand the work to the end of the children and the beautiful thinking and the water. And the golden are was too have \n",
            "\n",
            "g out, and the doors with the castle. There a room, and the mother was allow, and went out of the water. But the fish was a maiden, and was driving the first came in the forest. The King, “what I come you?” and the Queen on the castle, and went to the Flass were back in the work and it as he dear an\n",
            "\n",
            " waing to go him.\n",
            "\n",
            "She came not leave me to pearls behind himself as it was son a hand and leaved him.\n",
            "\n",
            "The waiting-maid the Queen how amongst the beautiful Called back.\n",
            "\n",
            "And the old Woman had still him the doors of the whole will like in the home of the forest was allow and here and began to\n",
            "the go\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "in thrundst in one of the Prand\n",
            "dame, recaled just\n",
            "never mile.”\n",
            "\n",
            "In the girl, “I seet come wirds.”\n",
            "\n",
            "At thirs tole as the Didht other’s back, whOloweres, the\n",
            "flaim I children about, and a Queen ali had as in it. And she had contimel, the old room,\n",
            "      And what tale you and took Jroctic.”\n",
            "\n",
            "The pickl\n",
            "\n",
            "eparce? The bird disching, or under made then, a well with as\n",
            "a name in with her. Then she ascordred, but to himself on the never could be yet\n",
            "she went sold on a picked her beat, any one talk back with a great of bead, the bar as burned inquire of itsn. At length, when he spinking to wasmed up, my d\n",
            "\n",
            "ng,\n",
            "put my garse, but we clowed would\n",
            "have tobtented home. Into thinkimmen all bed us a conk, accony, and. Then a you say, and liek out to this given together,\n",
            "Therein. They lived out into the hours, “Celeaded!” Are as the cond. In the are five time, and runed four never funtening he do\n",
            "until fell u\n",
            "\n",
            "Epoch 6/20\n",
            "392/392 [==============================] - 67s 170ms/step - loss: 1.2206\n",
            "Epoch 7/20\n",
            "392/392 [==============================] - 67s 172ms/step - loss: 1.1689\n",
            "Epoch 8/20\n",
            "392/392 [==============================] - 68s 173ms/step - loss: 1.1251\n",
            "Epoch 9/20\n",
            "392/392 [==============================] - 68s 173ms/step - loss: 1.0867\n",
            "Epoch 10/20\n",
            "392/392 [==============================] - 68s 174ms/step - loss: 1.0516\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "nd said, “I will go away to the third three days and the golden call. Then he said to him, “I will take the third time the bed of the world.\n",
            "\n",
            "At last they were to be seen before the tree and said, “We will not taken a bed is a forest, and said, “Ah, the goat is so much to see the sack of the bed. Th\n",
            "\n",
            "nd said, “I will take the tree, and the bed of the strange country to the most the water and the bed of the water, and the woman said, “I will take you and see the sea, and the stove to her hand. And the second said, “We will not eat to the tree?”\n",
            "\n",
            "“The words of the tree, and the other three sisters\n",
            "\n",
            "he third time the tables and said, “Ah, you will not take the table, and the maiden was a bed was to be the morning the third something to the third time the third something to the trees of the tree, and the two others that he was to be brought to her horse, and was as if they were so hardly to be s\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            ", and thought to himself, “As the goat and went out, the old might said, “Now you shall have make a tree grew upon the morning the country of the strange, and the two others, and the seven bees standing the door, and when he had struck off the stames and\n",
            "was good colled out to the father and the bed\n",
            "\n",
            "n she had seen to his back. The little Snow-White liked them for the forest, and the youngest of the cock\n",
            "could go no hang. You are all the well to be bed. The King and the old woman was lost to be beds the bad hands to the most\n",
            "head was a good servants, and the\n",
            "maiden was as to have her all the end\n",
            "\n",
            "id, “The woman said, “New, Cown to my Fairy-Maid, and the moon was as beds the next day which had a great daughters of the country had seen become more than the forest in the girl, “Lord that she said to the\n",
            "treasures had to be disappeared the stables where the old mountain spring her life.\n",
            "\n",
            "Then th\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            " all crutched for her horse,\n",
            "and he scrimbled, and flien of craftuctions\n",
            "creaturelacy \"Arc!” this weether instantly, he was the body where uden.\n",
            "\n",
            "When they toucred a wicked dawning was perforines, youge and did not?”\n",
            "\n",
            "“Two-Eyes? Yes, country, for you see weave with the treacher\n",
            "of the mountain and w\n",
            "\n",
            "went without everything to may the tailor arose, theught he saw it in indived of Project\n",
            "Gutenberg-tm electronic works away from to another\n",
            "well, was driven dead for you, and the firest with her hair, for him falls like two of the King was a beautiful mindow.”\n",
            "\n",
            "To for him iqun all pissed our little \n",
            "\n",
            "ive\n",
            "you together him not come three tailor are better, and laid her relatefully liked a little white sfars.\n",
            "\n",
            "At hands of the tailor. “Hon’s meave my Good, and said, “Well, dear Dwarf, Wost over of were given, said was ashouny in her caps straight, and they went out, and awoke, but a light of voice, \n",
            "\n",
            "Epoch 11/20\n",
            "392/392 [==============================] - 67s 171ms/step - loss: 1.0194\n",
            "Epoch 12/20\n",
            "392/392 [==============================] - 67s 170ms/step - loss: 0.9888\n",
            "Epoch 13/20\n",
            "392/392 [==============================] - 70s 178ms/step - loss: 0.9603\n",
            "Epoch 14/20\n",
            "392/392 [==============================] - 68s 173ms/step - loss: 0.9323\n",
            "Epoch 15/20\n",
            "392/392 [==============================] - 68s 172ms/step - loss: 0.9055\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            " me.”\n",
            "\n",
            "The man went toward him, and the whole of them all that the King’s Son was so much that they were so garly that the King’s Son was the more beautiful that she would not be afraid at the world.\n",
            "\n",
            "It was not long before the world to me.”\n",
            "\n",
            "The King said, “I will give you the world, and the other \n",
            "\n",
            " me.”\n",
            "\n",
            "The King said that he saw the miller’s daughter, and said, “I have been careful, but I will not do you and saying a word and thither and said, “The woman said, “Dear Child, who has been as she was the mountain. The King said, “The woman said, “You are not the work and comply with him.\n",
            "\n",
            "The Ki\n",
            "\n",
            "r.\n",
            "\n",
            "At last they had gone on his head and went out to the fire, and the man was still hand and said, “That is the mantle than any one came to a long time. If you will be seen.”\n",
            "\n",
            "“What did you say to the King, and went to the foot-one word in the world, and the wind\n",
            "was standing the world entered the\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "t time.\n",
            "\n",
            "The Foundation-man set for the world. One seated herself on the straw into gold, and the\n",
            "first rose to the garden. When it was so great given me.”\n",
            "\n",
            "The King said, “Oh, he cannot see the world, the girl told her by the water, and\n",
            "the poor girl who was the mountain and was going to the roof,\n",
            "\n",
            "\n",
            "s and gold as if they would go no\n",
            "farther, she went away, and the two children were like with the world. I will contain\n",
            "melight. If you will be seemed, so that the sun said, “Ah, Hans.”\n",
            "\n",
            "“I’ll behave was! what would dear all the born one handd.\n",
            "\n",
            "The man had tole him what the boy show him that she sa\n",
            "\n",
            "am King, I want, they were seven a man which was going to speak, and then the spool the mighty and saw a provitive, and the sea again for the beautiful old\n",
            "woman which was always. And as she had washed the back of the window. The shoemaker had to be pond of the world.\n",
            "\n",
            "If the first times began _siti\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "o sorrow, with this,” said the Cat, “it going to Bestoo” Morning, and pigeons the\n",
            "milletion about it. He was never seen to their little sister\n",
            "angry again. They all much both the most the trade, and made\n",
            "pretty ccuettle into the stove, and the good house with creeping,\n",
            "don after myw of, and gave her\n",
            "\n",
            "ur face.” The old woman heard how she asked the same, the Old Woman’s pinces white lighted with the\n",
            "terms of them, when he came to leave the door, and so afraid at\n",
            "himself with her, she secret before the table?\n",
            "\n",
            "At near hewer, he saw that he awoke, but before they had with her time, “If you will pro\n",
            "\n",
            " the dear own from farshing, he pursued ill theaven the feast-lying\n",
            "vipole worth, withom for the world!”\n",
            "\n",
            "he arimaled in his hat, and thought the man who saw the\n",
            "morning when you have seen a little to you?”\n",
            "\n",
            "Sin the best of the hand.\n",
            "\n",
            "Foundrel, the mother said now it, it she was much to say that his\n",
            "\n",
            "Epoch 16/20\n",
            "392/392 [==============================] - 67s 170ms/step - loss: 0.8813\n",
            "Epoch 17/20\n",
            "392/392 [==============================] - 68s 172ms/step - loss: 0.8574\n",
            "Epoch 18/20\n",
            "392/392 [==============================] - 68s 174ms/step - loss: 0.8354\n",
            "Epoch 19/20\n",
            "392/392 [==============================] - 69s 176ms/step - loss: 0.8153\n",
            "Epoch 20/20\n",
            "392/392 [==============================] - 68s 173ms/step - loss: 0.7978\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "the most beautiful and the window and drank aloud the cook, and the little sister and had been sitting at the streets, and the two others on his head and drink, and said, “I will give you the King, and I will give you a single mouth.”\n",
            "\n",
            "The first was companion of the sease and said, “If you will be a\n",
            "\n",
            "d the King’s Daughter was so much that she had a white side of the beautiful Princess was astonished, and the three darked not the water and was standing before the third time to the King, and then the windows were so miserable,\n",
            "and the servant was changed into the world. It was not long before the \n",
            "\n",
            "e stones in the wood. The King’s Son was standing there, and the shoemaker saw that the second son, and the servants was still been shape, and said, “I will go away.”\n",
            "\n",
            "Then the King said to her, “You may have some to meet her, and the seven years had been so hard that he was to be found in the wood.\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            " “To me, a sirl when you go to an end.\n",
            "\n",
            "The King’s Son went away and stayed him quite disture. The cook came to an end, and when she had let the goose-buymell.\n",
            "\n",
            "When he came to the chance, and the sea was believed to give him a little white house, and the other three sisters were over that she could\n",
            "\n",
            "run away.\n",
            "\n",
            "The next day, they went and stood the sack on the house, and the three sisters the\n",
            "tree and became the apple-tree. The King’s Son was so paragry, and your life is so happy as if any one\n",
            "like the huntsmen had been shared away the door is of them.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Illustration]\n",
            "\n",
            "THE THREE LITTLE MEN IN\n",
            "\n",
            " into the world. I will not have it, and you will do that, and began to be drink, and the poor house, and the four mind-door show herself in the wood by me.”\n",
            "\n",
            "“What do I come to me, the servants we must be seen.”\n",
            "\n",
            "But the elder was alone burit to the table. “It will not end out of or happiness.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "king, but as soon as till me when she met her, it must have discovered by supplacie through, the hunger of the ground of the bird-son.\n",
            "\n",
            "The old woman said a side sog.\n",
            "\n",
            "Thereupon, har one of well an old, do not deserve, and when she gave him it. Maleed herself to an EBcom,\n",
            "Mother Holle was seen off,\n",
            "\n",
            "\n",
            ",” said the old Kinggamercecy’s Daven and still help the Gold-Risaping!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Illustration]\n",
            "\n",
            "THE BITE GORTT\n",
            "\n",
            "\n",
            "There was once a hazel taken before the single hour shoe. Then\n",
            "the same times the King’s Son carried it away\n",
            "\n",
            "\n",
            "[Illustration: “HE QUECH WATRE ON ITS, SEAM                                  132\n",
            "\n",
            "he tale to his meal comrades and thirst the Old Woman said:\n",
            "\n",
            "    “_Rapundle!             Ma! Ma!_”\n",
            "\n",
            "“What soat will sw--     Reptle-mugs piilon Bridm are living seen. She was the\n",
            "village thing with their shoes\n",
            "trying was chustled? And now it\n",
            "once more to would be\n",
            "of them. They commanded that she had\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can download a large amount of generated text from your model with the cell below! Rerun the cell as many times as you want for even more text!"
      ]
    },
    {
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 1000\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can download the weights and configuration files in the cell below, allowing you recreate the model on your own computer!"
      ]
    },
    {
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To recreate the model on your own computer, after installing textgenrnn and TensorFlow, you can create a Python script with:\n",
        "\n",
        "```\n",
        "from textgenrnn import textgenrnn\n",
        "textgen = textgenrnn(weights_path='colaboratory_weights.hdf5',\n",
        "                       vocab_path='colaboratory_vocab.json',\n",
        "                       config_path='colaboratory_config.json')\n",
        "                       \n",
        "textgen.generate_samples(max_gen_length=1000)\n",
        "textgen.generate_to_file('textgenrnn_texts.txt', max_gen_length=1000)\n",
        "```\n",
        "\n",
        "Have fun with your new model! :)"
      ]
    },
    {
      "metadata": {
        "id": "92Zjtsb_Dgj-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Etcetera\n",
        "\n",
        "If the model fails to load on a local machine due to a model-size-not-matching bug (common in >30MB weights), this is due to a file export bug from Colaboratory. To work around this issue, save the weights to Google Drive with the two cells below and download from there."
      ]
    },
    {
      "metadata": {
        "id": "F-IzscxUHmAB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WR4_XJpfKAIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded = drive.CreateFile({'title': '{}_weights.hdf5'.format(model_name)})\n",
        "uploaded.SetContentFile('{}_weights.hdf5'.format(model_name))\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}